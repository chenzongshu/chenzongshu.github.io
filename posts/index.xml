<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 蜗牛龙门阵</title>
    <link>https://chenzongshu.github.io/posts/</link>
    <description>Recent content in Posts on 蜗牛龙门阵</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 04 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://chenzongshu.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>容器江湖闲话</title>
      <link>https://chenzongshu.github.io/posts/%E5%AE%B9%E5%99%A8%E6%B1%9F%E6%B9%96%E9%97%B2%E8%AF%9D/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E5%AE%B9%E5%99%A8%E6%B1%9F%E6%B9%96%E9%97%B2%E8%AF%9D/</guid>
      <description>引子 江湖永远不缺乏刀光剑影，鼓角争鸣。可能杰夫·贝佐斯不曾想到，他推出的AWS成了全球云计算IaaS和PaaS的霸主，从根本上改变了IT江湖的格局。
但是各路诸侯从未放弃自己的勃勃野心
近几年，云原生概念的提出，容器和kubernetes已经被炒作的非常火热了，甚至传统行业都开始拥抱容器，采用容器平台作为其基础架构
容器这片江湖也是经历过各方大佬的博弈厮杀，才形成了这样的局面，这回书，我们就来摆摆龙门阵，聊聊大佬们的江湖
风起微末 2013年，PaaS盛行于江湖，
一个名字叫dotCloud的小”帮派“凭着东拼西凑的招式混口饭吃，在混不下去之际，决定把自己的武功心法公布于众，开源自己的容器项目Docker，没想到，短短几个月，各路豪强竟然纷纷来投，凭借的，就是自己发明的新招式：Docker镜像
PaaS的武器就是可执行程序加上启停脚本，常常为不同环境需要折腾不同配置的问题搞的焦头烂额，而Docker镜像打包了一个文件系统和目录，包含了你所需要的所有依赖，就这一个小招式，打通了开发者应用部署的任督二脉，从此踏上争霸之路。
金鳞岂是池中物，一遇风云便化龙
群雄争霸 Docker虽然风头无双，但是帮派内部人士一直有所担心，毕竟Docker只是底层，是内功心法，各位大侠真正愿意是付费是产品，是平台，野蛮生长的Docker当然不甘心做垫脚石，于是乎把主意打上了其他人的蛋糕。
Docker接着发布了Swarm、Compose、Machine三板斧，想吞下容器生态圈。同时，2014年底，因为Docker意欲染指更多容器平台能力，Docker和另一大势力CoreOS决裂。
CoreOS的核心招式就是提供定制化OS，分布式部署和管理节点，本来想把Docker集成到其中，做了很多贡献，立下了汗马功劳，坐第二把交椅。反出梁山之后，发布了rkt，不过没掀起多大浪花就被拍死了。
老牌豪强Mesos也看准了这波容器化浪潮，推出了Marathon项目，打出了mesos + marathon + docker的组合拳，其核心的资源调度mesos框架又是久经沙场的考验，于是乎有一种振臂一呼，天下英雄群起响应的声音。我前东家至今还有用这个做的容器平台，上面跑了4w容器实例。
坐第三把交椅的Redhat也是Docker早期的重要贡献者，不满Docker的平台化战略而退出。虽然Redhat在PaaS浪潮中没有多少牌可以打，但是其本身深谙开源之道，在OS方面有较大话语权，这也为Docker的衰败埋下了了伏笔，因为Redhat收购CoreOS之后，在Kubernetes的累计PR贡献榜上足有15541个，排第三的华为才3111（排第一个的谷歌是36371），可谓江湖报仇，三年不晚。</description>
    </item>
    
    <item>
      <title>六、监控体系</title>
      <link>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E5%85%AD%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Thu, 21 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E5%85%AD%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/</guid>
      <description>前言 监控也是运维体系中的重要的一环，云原生的监控体系基本是基于Promethus为核心的体系打造，这里我们使用kube-promethus项目
kube-prometheus 是一整套监控解决方案，它使用 Prometheus 采集集群指标，Grafana 做展示，包含如下组件：
 The Prometheus Operator Highly available Prometheus Highly available Alertmanager Prometheus node-exporter Prometheus Adapter for Kubernetes Metrics APIs （k8s-prometheus-adapter） kube-state-metrics Grafana  部署 安装 下载，注意不同版本对应不同Kubernetes版本，注意切换版本</description>
    </item>
    
    <item>
      <title>二、kubeadm安装Kubernetes</title>
      <link>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%BA%8Ckuberadmin%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%BA%8Ckuberadmin%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/</guid>
      <description>准备 禁用swap Kubernetes 1.8开始要求必须禁用Swap，如果不关闭，默认配置下kubelet将无法启动。
vim /etc/fstab # / was on /dev/sda1 during installation UUID=8cc33106-20fc-43b7-ad52-298eed8ccae6 / ext4 errors=remount-ro 0 1 #/swapfile none swap sw 0 0 把swapfile行注释掉后执行</description>
    </item>
    
    <item>
      <title>五、EFK</title>
      <link>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%BA%94efk/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%BA%94efk/</guid>
      <description>前言 在私有云平台中，日志系统也是重要的一部分，采集收集归纳是必不可少的，在kubernetes容器云中，我们采用标准的EFK来集成。
日志系统有多种套件，ELK（Elasticsearch、Logstash、Kibana）和EFK（Elasticsearch、Filebeat/Fluent、Kibana）, 其中ES是日志存储分析的核心引擎，在搜索领域应用也非常广泛， Logstash/Filebeat/Fluent是日志的采集端，不过Filebeat/Fluent更加轻量级，对资源消耗更小，各大公有云厂商都是自研的采集插件
在大型的日志系统中，日志量过大时，ES前端往往会集成kafka或者redis，用于缓存日志数据。在私有云中，我们只需要ES配合采集端加上Kibana显示就可以了
ES安装 为了简化过程我们通过Helm来安装ES, 官方chart地址为 https://github.com/elastic/helm-charts ， 可以从helm的repo源下载也可以直接从github上下载chart
增加官方repo源地址
helm repo add elastic https://helm.elastic.co 下载chart
helm fetch elastic/elasticsearch 或者从github下载对应分支，这里采用github上下载的chart</description>
    </item>
    
    <item>
      <title>四、Harbor镜像仓库</title>
      <link>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E5%9B%9Bharbor/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E5%9B%9Bharbor/</guid>
      <description>我们在私有云中，往往需要构建自己的私有镜像，以提高镜像下载速度，而且结合CICD流程，方便构建流水线, 这里我们使用Harbor, 比起Docker原生的registry, 增加了权限管理, 镜像同步等功能, 比较适合生产应用
Harbor官网有两种搭建方式 , 一种是使用Helm Chart, 一种是用docker compose
对应的, 使用Chart来搭建的, 就是搭建在集群内部, docker compose搭建在集群外部
Kubernetes搭建 添加仓库 helm repo add harbor https://helm.</description>
    </item>
    
    <item>
      <title>三、Helm和Ingress</title>
      <link>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%B8%89helm%E5%92%8Cingress/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%B8%89helm%E5%92%8Cingress/</guid>
      <description>前言 在第二篇里面，我们安装了kubernetes集群和calico网络组件，一个基本的kubernetes集群已经能够正常工作了，但是在生产实际中，这是远远不够的，这篇里面，我们来安装Helm、ingress组件、Harbor、EFK、prometheus
为了方便，我们使用Helm的chart来安装 ingress、harbor、EFK和Prometheus
Helm 安装 可以到GitHub官网下载： https://github.com/helm/helm/releases ， 选择对应的版本即可，我们为了方便安装Helm3.X的版本
注意：
 Helm 3.X只有一个客户端, 必须放到可以使用kubectl的环境 Helm 2.X有服务端tiller，提供Restful接口，可以方便自有的平台对接  helm仓库 首次安装 helm 3 是没有指定默认仓库的。需要手动疯狂添加仓库才可以获取到程序包。可以用下面命令查看</description>
    </item>
    
    <item>
      <title>一、容器云架构介绍</title>
      <link>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%B8%80%E5%AE%B9%E5%99%A8%E4%BA%91%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E6%90%AD%E5%BB%BA%E5%AE%B9%E5%99%A8%E4%BA%91%E4%B9%8B%E4%B8%80%E5%AE%B9%E5%99%A8%E4%BA%91%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/</guid>
      <description>前言 以docker和kubernetes为代表的的容器技术现在在市场上接受度越来越高，业界现在也有较多成熟产品，公有云有阿里华为腾通，私有云有OpenShift，才云，青云kubesphere，Rancher，灵雀云都做的不错， 为什么我们还折腾自建的容器平台？
 1、自己搭建过的东西更加有掌控力，据我交流，不少公司在体量到了一定程度之后都走上了自建的道路 2、自己搭建过后才对整体框架有了一个清晰的认知。  主要是结合自己的理解和实践，手把手教还不太熟悉容器的同学搭建一套自己的容器平台
什么是容器云 不想去拷贝网上的各种文章，简单说下自己的理解，VM和容器的优劣不想过多讨论，但是谷歌错过了云计算的浪潮，让AWS占据先机之后，大力推动容器技术，也是想争夺话语权。至于docker和各个巨头的腥风血雨，更是一言难尽。
现在的容器云标准几乎就是以kubernetes为编排工具调度容器运行到虚拟机或者物理机上，对计算资源进行编排的一套技术，最后取了一个牛掰哄哄的名字：云原生 （虽然云原生是Pivotal提出的，但是谷歌成立的CNCF把这概念推广开）
业界主流容器云 这里特指私有云，当然私有云也可以搭建在公有云服务器上，组成混合云
总体来说，各家技术框架大同小异，都是围绕着kubernetes生态做了挺多外围工作，
  OpenShift
红帽的技术实力毋庸置疑，OpenShift 3.x和4.x部署架构区别较大，特别是4.x，OS必须为CoreOS，容器运行时也是主推rkt，虽然做了不少优化，用了25个operator来部署，对于自行运维，想了解部署、架构、细节的朋友实在是太不友好，问题定位较麻烦，多说一句，4.x必须联网才能部署</description>
    </item>
    
    <item>
      <title>Etcd源码分析之磁盘写入及操作</title>
      <link>https://chenzongshu.github.io/posts/etcd%E7%A3%81%E7%9B%98%E5%86%99%E5%85%A5%E5%8F%8A%E6%93%8D%E4%BD%9C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/etcd%E7%A3%81%E7%9B%98%E5%86%99%E5%85%A5%E5%8F%8A%E6%93%8D%E4%BD%9C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>Etcd磁盘要求 官方原文链接: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md
Etcd对磁盘写入延时非常敏感
高速磁盘是保证etcd部署性能和稳定性的关键因素。
慢磁盘会增加etcd的请求延时，潜在影响集群的稳定性。因为etcd一致性协议依赖于元数据写入持久化日志，并且要求集群大多数成员将请求写入磁盘。此外，etcd还会到磁盘上增量检查集群的状态，从而可以截断日志。如果这些写操作花费太长的时间，心跳就可能会超时，触发选举操作，从而破坏集群的稳定性。
etcd对磁盘写入延时非常敏感。通常稳定达到50 IOPS（比如：一个7200转的磁盘）是必须的，对于负载很高的集群，推荐能稳定达到500 IOPS（比如：一个典型的本地SSD盘或者高性能的虚拟块设备盘）。注意，大多数云服务提供商发布的是瞬时并发IOPS，并不是稳定的IOPS，瞬时并发IOPS可能十倍于稳定连续的IOPS（说明：因为瞬时并发IOPS可能会写缓存，或者测试时无其他用户竞争磁盘资源，所以会很高，当测试时间很长后，就会测试出设备的真实IOPS能力，这个在国内云厂商基本没有这个问题）。测试稳定连续IOPS，我们建议使用磁盘基准测试工具，比如 diskbench 或者 fio。
etcd对磁盘带宽没什么要求，但是更大的磁盘带宽可以在失败节点加入集群时，更快的完成恢复操作。通常10MB/s带宽的磁盘15s可以恢复100MB的数据，对于大型集群，100MB/s或更高带宽的磁盘可以在15s内恢复1GB数据。
如果有可能，etcd后端存储就用SSD。一个SSD磁盘和机械盘相比，通常会提供更低的写入延时和更少的数据跳变（variance），因此可以提高etcd集群的稳定性和可靠性。如果使用机械盘，尽可能使用最快的（15000转）。使用RAID 0也是一种有效提高磁盘性能的方法，不管是机械盘还是SSD都可以。etcd集群至少有3个节点，磁盘使用RAID做镜像或者做奇偶校验都是不必要的，因为etcd自身的一致性复制已经保证了数据的高可用。
Etcd日志写入 etcd的存储分为内存存储和持久化（硬盘）存储两部分，内存中的存储除了顺序化地记录下所有用户对节点数据变更的记录外，还会对用户数据进行索引、建堆等方便查询的操作。而持久化则使用预写式日志（WAL：Write Ahead Log）进行记录存储。
在WAL的体系中，所有的数据在提交之前都会进行日志记录。在etcd的持久化存储目录中，有两个子目录。一个是WAL，存储着所有事务的变化记录；另一个则是snapshot，用于存储某一个时刻etcd所有目录的数据。通过WAL和snapshot相结合的方式，etcd可以有效地进行数据存储和节点故障恢复等操作。</description>
    </item>
    
    <item>
      <title>Etcd源码分析之存储</title>
      <link>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%AD%98%E5%82%A8/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%AD%98%E5%82%A8/</guid>
      <description>存储数据结构 Etcd存储在集群搭建和使用篇有简介，总结起来有如下特点：
 采用kv型数据存储，一般情况下比关系型数据库快。 支持动态存储(内存)以及静态存储(磁盘)。 分布式存储，可集成为多节点集群。 存储方式，采用类似目录结构。 1、只有叶子节点才能真正存储数据，相当于文件。 2、叶子节点的父节点一定是目录，目录不能存储数据。  叶子节点数据结构位于 /store/store.go
type store struct { Root *node WatcherHub *watcherHub CurrentIndex uint64 Stats *Stats CurrentVersion int ttlKeyHeap *ttlKeyHeap // need to recovery manually worldLock sync.</description>
    </item>
    
    <item>
      <title>Etcd源码分析之put流程</title>
      <link>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Bput%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Bput%E6%B5%81%E7%A8%8B/</guid>
      <description>put操作 put操作是etcd v3 client支持的命令，和v2的set用法差不多
但是需要注意的是，如果你在一个3节点的etcd集群中，A节点切换为v3 client版本，然后put进了一对key-value，在B节点，还是v2的client，这个时候你get不到数据的，如果在B节点切换到了v3 client，这个时候才可以get到数据
简单的说，v2和v3 client，插入数据到同一个etcd集群中，数据不能互通
put流程分析 client端 put命令接受的入口，在/etcdctl/ctlv3/command/put_command.go中的NewPutCommand()函数中，采用了一个corba结构体接受命令参数，实际Run执行的命令是putCommandFunc()
func putCommandFunc(cmd *cobra.Command, args []string) { key, value, opts := getPutOp(cmd, args) //解析参数 ctx, cancel := commandCtx(cmd) resp, err := mustClientFromCmd(cmd).</description>
    </item>
    
    <item>
      <title>Etcd源码分析之raft协议</title>
      <link>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Braft%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Braft%E5%8D%8F%E8%AE%AE/</guid>
      <description>以etcd或者docker中的raft协议为列子,来解析raft协议的实际落地
server通信 概述 server之前的消息传递并不是简单的request-response模型，而是读写分离模型，
即每两个server之间会建立两条链路，对于每一个server来说，一条链路专门用来发送数据，另一条链路专门用来接收数据.
在代码实现中，通过streamWriter发送数据，通过streamReader接收数据。即通过streamReader接收数据接收到数据后会直接响应，在处理完数据后通过streamWriter将响应发送到对端
对于每个server来说，不管是leader、candicate还是follower，都会维持一个peers数组，每个peer对应集群中的一个server，负责处理server之间的一些数据交互。
当server需要向其他server发送数据时，只需要找到其他server对应的peer，然后向peer的streamWriter的msgc通道发送数据即可，streamWriter会监听msgc通道的数据并发送到对端server；
而streamReader会在一个goroutine中循环读取对端发送来的数据，一旦接收到数据，就发送到peer的p.propc或p.recvc通道，而peer会监听这两个通道的事件，写入到node的n.propc或n.recvc通道，node只需要监听这两个通道的数据并处理即可。这就是在etcd的raft实现中server间数据交互的流程。
启动监听 对于每个server，都会创建一个raftNode，并且启动一个goroutine，执行raftNode的serveRaft方法
func (rc *raftNode) serveRaft() { ...... err = (&amp;amp;http.Server{Handler: rc.</description>
    </item>
    
    <item>
      <title>Etcd源码分析之网络</title>
      <link>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E7%BD%91%E7%BB%9C/</guid>
      <description>配置文件 etcd配置文件位于/etc/etcd/etcd.conf,该配置文件一共有5个section
   名称 作用     member 本节点的配置，包括监听服务端口、心跳时间等   cluster 集群配置，包括集群状态、集群名称以及本节点广播地址   proxy 用于网络自动发现服务   security 安全配置   logging 日志功能组件    具体配置采集可以见另一个文章《Etcd集群配置和使用》</description>
    </item>
    
    <item>
      <title>Etcd源码分析之启动篇</title>
      <link>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%90%AF%E5%8A%A8%E7%AF%87/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://chenzongshu.github.io/posts/etcd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E5%90%AF%E5%8A%A8%E7%AF%87/</guid>
      <description>启动 启动从源码 /etcdmain/main.go 中的main函数开始
func Main() { checkSupportArch() // 检查系统是否支持 if len(os.Args) &amp;gt; 1 { // 获取入参 cmd := os.Args[1] // 获取启动命令 if covArgs := os.</description>
    </item>
    
  </channel>
</rss>
